# Machine-Learning-Health-Classification

## Description du Projet

Ce projet vise √† analyser un dataset de sant√© et bien-√™tre pour classifier les individus en trois cat√©gories selon leur √©tat de sant√©. On utilise des techniques de **machine learning** comme **KNN**, **r√©gression logistique**, **arbre de d√©cision** et **KMeans** pour effectuer cette classification.

### Objectif
Le but est de classifier les individus en trois cat√©gories selon leur √©tat de sant√© :
- **Classe 0 : Sain et Actif**
- **Classe 1 : Mod√©r√©**
- **Classe 2 : √Ä Risque**

Nous cherchons √† comprendre comment diff√©rents facteurs influencent la sant√© des individus √† partir des donn√©es disponibles.

## Structure du Dataset

Le dataset contient **10 000 observations** et **20 variables explicatives** qui repr√©sentent des indicateurs cl√©s, comme :
- √Çge, Taille, Poids, Revenu, IMC, Niveau de stress, Cholest√©rol, etc.

La **variable cible** classe les individus en trois cat√©gories :
- **Classe 0 : Sain et Actif** üü¢
- **Classe 1 : Mod√©r√©** üü°
- **Classe 2 : √Ä Risque** üî¥

## √âtapes de l'Analyse

### 1. **Pr√©traitement des Donn√©es**
- S√©paration des variables explicatives et de la cible.
- **Standardisation des donn√©es** avec `StandardScaler` pour que toutes les variables aient la m√™me √©chelle.

### 2. **R√©duction de Dimensionnalit√© avec PCA**
- Utilisation de la **PCA** pour r√©duire les dimensions des donn√©es tout en gardant 95% de la variance.
- Visualisation des donn√©es en 2D et 3D pour mieux comprendre la r√©partition des individus.

### 3. **Mod√©lisation Supervis√©e**
- **KNN (K-Nearest Neighbors)** : Classification bas√©e sur la proximit√© des points.
- **R√©gression Logistique** : Pr√©diction de la probabilit√© d'appartenance √† chaque classe.
- **Arbre de D√©cision** : Mod√®le visuel et interpr√©table pour la classification.

### 4. **Optimisation des Mod√®les avec Grid Search**
- **KNN** : Recherche du meilleur nombre de voisins.
- **Arbre de D√©cision** : Optimisation de la profondeur et des crit√®res de s√©paration avec **GridSearchCV**.

### 5. **Clustering Non Supervis√© avec K-Means**
- Application de **KMeans** pour regrouper les individus en clusters sans utiliser la variable cible.
- Utilisation de la **m√©thode du coude** pour d√©terminer le nombre optimal de clusters et √©valuation de la qualit√© du clustering avec l'indice de **silhouette**.

### 6. **Validation Crois√©e**
- Utilisation de la **validation crois√©e** √† 5 plis pour √©valuer la stabilit√© et les performances des mod√®les (KNN, r√©gression logistique, arbre de d√©cision).

## Outils et Librairies Utilis√©es
- **Python 3.x**
- **pandas, numpy** : Manipulation des donn√©es
- **matplotlib, seaborn** : Visualisation des donn√©es
- **sklearn** : Machine Learning (PCA, KNN, R√©gression Logistique, Arbre de D√©cision, KMeans)
- **GridSearchCV** : Optimisation des hyperparam√®tres

---

### Conclusion

Ce projet m'a permis d'utiliser des techniques de **machine learning** pour classifier des individus en fonction de leur √©tat de sant√©. J'ai test√© plusieurs mod√®les supervis√©s (KNN, r√©gression logistique, arbre de d√©cision) et une approche non supervis√©e (KMeans). Les r√©sultats montrent que KNN et r√©gression logistique ont bien perform√© sur les donn√©es, tandis que KMeans n'a pas parfaitement identifi√© les clusters en raison de la faible qualit√© de la s√©paration.

### Am√©liorations possibles
- **Optimisation plus approfondie des hyperparam√®tres** pour tous les mod√®les.
- **Utilisation d'autres techniques de r√©duction de dimension** comme **t-SNE** pour am√©liorer la visualisation.
- **Am√©liorer la visualisation des r√©sultats** pour mieux comprendre les relations entre les clusters et les classes.

---

### Pistes d'am√©lioration :
- Tester davantage de param√®tres pour chaque mod√®le avec **GridSearchCV**.
- Explorer d'autres m√©thodes de clustering pour comparer avec KMeans.

